---
title: "Project4"
output:
  html_document:
    df_print: paged
  pdf_document: default
---


### Step 1 Load Data and Train-test Split
```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
data <- read.csv("../data/ml-latest-small/ratings.csv")
set.seed(0)
test_idx <- sample(1:nrow(data), round(nrow(data)/5, 0))
train_idx <- setdiff(1:nrow(data), test_idx)
data_train <- data[train_idx,]
data_test <- data[test_idx,]
```

###Step 2 Matrix Factorization
#### Step 2.1 A1+P3

A1. [Stochastic Gradient Descent](./paper/P1 Recommender-Systems.pdf) Section: Learning Algorithms-Stochastic Gradient Descent



```{r}
U <- length(unique(data$userId))
I <- length(unique(data$movieId))
source("../lib/Matrix_Factorization_A1.R")
```


#### Step 2.1.1 Parameter Tuning
According to the cross validation, the best tunning patameterr is f=10, lambda= 0.1
```{r}
source("../lib/cross_validation.R")
f_list <- seq(10, 20, 10)
l_list <- seq(-2, -1, 1)
f_l <- expand.grid(f_list, l_list)
```


```{r, eval=FALSE}
#result_summary_A1 <- array(NA, dim = c(nrow(f_l), 10, 4))

#run_time_A1 <- system.time(for(i in 1:nrow(f_l)){
    #par <- paste("f = ", f_l[i,1], ", lambda = ", 10^f_l[i,2])
    #cat(par, "\n")
    #current_result <- cv.function(data, K = 5, f = f_l[i,1], lambda = 10^f_l[i,2])
    #result_summary[,,i] <- matrix(unlist(current_result), ncol = 10, byrow = T) 
    #print(result_summary)
#})

#save(result_summary, file = "../output/rmse.Rdata")
```

```{r}
load("../output/rmse.Rdata")
rmse <- data.frame(rbind(t(result_summary[1,,]), t(result_summary[2,,])), train_test = rep(c("Train", "Test"), each = 4), par = rep(paste("f = ", f_l[,1], ", lambda = ", 10^f_l[,2]), times = 2)) %>% gather("epoch", "RMSE", -train_test, -par)
rmse$epoch <- as.numeric(gsub("X", "", rmse$epoch))
rmse %>% ggplot(aes(x = epoch, y = RMSE, col = train_test)) + geom_point() + facet_grid(~par)
```

#### Step 2.1.2 Using the best parameter: f=10, lambda=0.1 and save the result
```{r, eval= FALSE}
#result <- gradesc(f = 10, lambda = 0.1,lrate = 0.01, max.iter = 100, stopping.deriv = 0.01,
                   #data = data, train = data_train, test = data_test)

#save(result, file = "../output/mat_fac_A1.RData")

```

### Step 2.1.3 Evaluation on the Model without Postprocessing
visualize training and testing RMSE by different epochs
```{r}
load(file = "../output/mat_fac.RData")
library(ggplot2)

RMSE <- data.frame(epochs = seq(10, 100, 10), Training_MSE = result$train_RMSE, Test_MSE = result$test_RMSE) %>% gather(key = train_or_test, value = RMSE, -epochs)

RMSE %>% ggplot(aes(x = epochs, y = RMSE,col = train_or_test)) + geom_point() + scale_x_discrete(limits = seq(10, 100, 10)) + xlim(c(0, 100))
```

### Step 2.1.4 P3 Postprocessing
After matrix factorization, postporcessing will be performed to improve accuracy.

P3:[Postprocessing SVD with kernel ridge regression](./paper/P2 Improving regularized singular value decomposition for collaborative filtering .pdf) Section 3.6


```{r}
source('../lib/Post_Process_P3.r')
load(file = "../output/mat_fac_A1.RData")

pred_rating_A1=t(result$q) %*% result$p
X=X_mat(result$q)
n=nrow(X)
lambda=0.5
#A1_P3_rating=svd_krr(n=n,lambda=lambda,X=X,y=pred_rating_A1)
#save(A1_P3_rating,file='../output/A1_P3_rating.RData')
#save the result to accelerate.

load('../output/A1_P3_rating.RData')

#define a function to extract the corresponding predictedrating for the test set.
extract_pred_rating <- function(test_set, pred){
  pred_rating <- pred[as.character(test_set[2]), as.character(test_set[1])]
  return(pred_rating)
}
#extract predicted rating
pred_test_rating_A1 <- apply(data_test, 1, extract_pred_rating, A1_P3_rating)

```


```{r}
rmse_mat=function(P,Y){
  return (sqrt(mean((P-Y)^2)))
}

#mean(P)
pred_mean_A1 <- mean(pred_test_rating_A1)
#mean(test)
mean_test_rating <- mean(data_test$rating)

#mean(test) - mean(P)
mean_diff <- mean_test_rating - pred_mean_A1

data_test$pred <- pred_test_rating_A1
data_test$pred_adj <- pred_test_rating_A1 + mean_diff

boxplot(data_test$pred_adj ~ data_test$rating)
#calculate RMSE
rmse_A1=rmse_mat(P=data_test$rating,Y=pred_rating_A1)
rmse_A1_P3=rmse_mat(P=data_test$rating,Y=A1_P3_rating)

cat("The RMSE of the adjusted model changes from ", rmse_A1, 'to',rmse_A1_P3)
```

#### Step 2.2 A2+P3
A2. [Gradient Descent with Probabilistic Assumptions](./paper/P3 probabilistic-matrix-factorization.pdf) Section 2
